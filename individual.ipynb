{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "0bf2d8b7",
      "metadata": {
        "id": "0bf2d8b7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDcItZXoNhTN",
        "outputId": "de6790db-3e23-4406-e00f-4774a72d304d"
      },
      "id": "TDcItZXoNhTN",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "importing libraries"
      ],
      "metadata": {
        "id": "W9BFsF0wN93W"
      },
      "id": "W9BFsF0wN93W"
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip3 install transformers\n",
        "#!pip3 install sentencepiece"
      ],
      "metadata": {
        "id": "NscesWPDN8Uv"
      },
      "id": "NscesWPDN8Uv",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers[sentencepiece] datasets sacrebleu rouge_score py7zr -q"
      ],
      "metadata": {
        "id": "aE0qUk5HN8v3"
      },
      "id": "aE0qUk5HN8v3",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "#from datasets import load_dataset\n",
        "from datasets import load_metric\n",
        "\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "\n",
        "\n",
        "from tqdm import tqdm\n",
        "import torch\n"
      ],
      "metadata": {
        "id": "UOMO2V9mN83F"
      },
      "id": "UOMO2V9mN83F",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oe2zOovCN87m",
        "outputId": "b21c35c8-a129-46e9-9655-a397c5187f29"
      },
      "id": "Oe2zOovCN87m",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: nvidia-smi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "ir5lEdyqOeh0"
      },
      "id": "ir5lEdyqOeh0",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_batch_sized_chunks(list_of_elements, batch_size):\n",
        "    \"\"\"split the dataset into smaller batches that we can process simultaneously\n",
        "    Yield successive batch-sized chunks from list_of_elements.\"\"\"\n",
        "    for i in range(0, len(list_of_elements), batch_size):\n",
        "        yield list_of_elements[i : i + batch_size]\n"
      ],
      "metadata": {
        "id": "dpUDVL5FOekL"
      },
      "id": "dpUDVL5FOekL",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_metric_on_test_ds(dataset, metric, model, tokenizer, \n",
        "                               batch_size=8, device=device, \n",
        "                               column_text=\"article\", \n",
        "                               column_summary=\"highlights\"):\n",
        "    article_batches = list(generate_batch_sized_chunks(dataset[column_text], batch_size))\n",
        "    target_batches = list(generate_batch_sized_chunks(dataset[column_summary], batch_size))\n",
        "\n",
        "    for article_batch, target_batch in tqdm(\n",
        "        zip(article_batches, target_batches), total=len(article_batches)):\n",
        "        \n",
        "        inputs = tokenizer(article_batch, max_length=1024,  truncation=True, \n",
        "                        padding=\"max_length\", return_tensors=\"pt\")\n",
        "        \n",
        "        # Filter out examples with a shorter sequence length\n",
        "        #mask = inputs['attention_mask'].sum(dim=1) > 0\n",
        "        #inputs = {k: v[mask] for k, v in inputs.items()}\n",
        "        #target_batch = [t for t, m in zip(target_batch, mask) if m]\n",
        "        \n",
        "        print(\"input_ids shape:\", inputs[\"input_ids\"].shape)\n",
        "        print(\"max input_ids value:\", inputs[\"input_ids\"].max())\n",
        "        print(\"vocabulary size:\", tokenizer.vocab_size)\n",
        "\n",
        "        summaries = model.generate(input_ids=inputs[\"input_ids\"].to(device),\n",
        "                         attention_mask=inputs[\"attention_mask\"].to(device), \n",
        "                         length_penalty=0.8, num_beams=8, max_length=128)\n",
        "        ''' parameter for length penalty ensures that the model does not generate sequences that are too long. '''\n",
        "       \n",
        "        print(summaries.shape)\n",
        "        print(inputs[\"attention_mask\"].shape)\n",
        "        # Finally, we decode the generated texts, \n",
        "        # replace the <n> token, and add the decoded texts with the references to the metric.\n",
        "        decoded_summaries = [tokenizer.decode(s, skip_special_tokens=True, \n",
        "                                clean_up_tokenization_spaces=True) \n",
        "               for s in summaries]      \n",
        "        \n",
        "        decoded_summaries = [d.replace(\"<n>\", \" \") for d in decoded_summaries]\n",
        "              \n",
        "        metric.add_batch(predictions=decoded_summaries, references=target_batch)\n",
        "        \n",
        "    #  Finally compute and return the ROUGE scores.\n",
        "    score = metric.compute(use_stemmer=True)\n",
        "    return score"
      ],
      "metadata": {
        "id": "wqRpiSEcOemt"
      },
      "id": "wqRpiSEcOemt",
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]\n",
        "\n",
        "rouge_metric = load_metric('rouge')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMdTbLg9Oeo_",
        "outputId": "fbe5fcef-cc0e-4962-86b9-9ca549b0d3ea"
      },
      "id": "yMdTbLg9Oeo_",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-67199026c897>:3: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
            "  rouge_metric = load_metric('rouge')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import PegasusForConditionalGeneration, PegasusTokenizer, Trainer, TrainingArguments\n"
      ],
      "metadata": {
        "id": "FbPgXTf9OerQ"
      },
      "id": "FbPgXTf9OerQ",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PegasusDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels['input_ids'][idx])  # torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ],
      "metadata": {
        "id": "7IwSnQkcPRtv"
      },
      "id": "7IwSnQkcPRtv",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data(model_name, \n",
        "                 train_texts, train_labels, \n",
        "                 val_texts, val_labels, \n",
        "                 test_texts=None, test_labels=None):\n",
        "  \"\"\"\n",
        "  Prepare input data for model fine-tuning\n",
        "  \"\"\"\n",
        "  tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
        "\n",
        "  prepare_val = False if val_texts is None or val_labels is None else True\n",
        "  prepare_test = False if test_texts is None or test_labels is None else True\n",
        "\n",
        "  def tokenize_data(texts, labels):\n",
        "    encodings = tokenizer(texts, truncation=True, padding=True)\n",
        "    decodings = tokenizer(labels, truncation=True, padding=True)\n",
        "    dataset_tokenized = PegasusDataset(encodings, decodings)\n",
        "    return dataset_tokenized\n",
        "\n",
        "  train_dataset = tokenize_data(train_texts, train_labels)\n",
        "  val_dataset = tokenize_data(val_texts, val_labels) if prepare_val else None\n",
        "  test_dataset = tokenize_data(test_texts, test_labels) if prepare_test else None\n",
        "\n",
        "  return train_dataset, val_dataset, test_dataset"
      ],
      "metadata": {
        "id": "NQ5u0ONDPRwo"
      },
      "id": "NQ5u0ONDPRwo",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_fine_tuning(model_name, train_dataset, val_dataset, freeze_encoder=False, output_dir='./results'):\n",
        "  \"\"\"\n",
        "  Prepare configurations and base model for fine-tuning\n",
        "  \"\"\"\n",
        "  torch_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "  model = PegasusForConditionalGeneration.from_pretrained(model_name).to(torch_device)\n",
        "\n",
        "  if freeze_encoder:\n",
        "    for param in model.model.encoder.parameters():\n",
        "      param.requires_grad = False\n",
        "\n",
        "  if val_dataset is not None:\n",
        "    training_args = TrainingArguments(\n",
        "      output_dir=output_dir,           \n",
        "      adafactor=True,                  \n",
        "      num_train_epochs=20,           \n",
        "      per_device_train_batch_size=2,   \n",
        "      per_device_eval_batch_size=2,   \n",
        "      save_steps=5,                  \n",
        "      save_total_limit=5,              \n",
        "      evaluation_strategy='steps',     \n",
        "      eval_steps=5,                  \n",
        "      warmup_steps=500,  \n",
        "      learning_rate=0.0002,              \n",
        "      weight_decay=0.01,              \n",
        "      logging_dir='./logs',            \n",
        "      logging_steps=10,\n",
        "      gradient_accumulation_steps=4\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "      model=model,                         \n",
        "      args=training_args,                  \n",
        "      train_dataset=train_dataset,         \n",
        "      eval_dataset=val_dataset             \n",
        "    )\n",
        "\n",
        "  else:\n",
        "    training_args = TrainingArguments(\n",
        "      output_dir=output_dir,           # output directory\n",
        "      adafactor=True,                  # use adafactor instead of AdamW\n",
        "      num_train_epochs=1,           # total number of training epochs\n",
        "      per_device_train_batch_size=1,   # batch size per device during training, can increase if memory allows\n",
        "      save_steps=100,                  # number of updates steps before checkpoint saves\n",
        "      save_total_limit=5,              # limit the total amount of checkpoints and deletes the older checkpoints\n",
        "      warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
        "      weight_decay=0.01,               \n",
        "      logging_dir='./logs',            \n",
        "      logging_steps=10,\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "      model=model,                         # the instantiated 🤗 Transformers model to be trained\n",
        "      args=training_args,                  # training arguments, defined above\n",
        "      train_dataset=train_dataset,         # training dataset\n",
        "    )\n",
        "\n",
        "  return trainer"
      ],
      "metadata": {
        "id": "uu6kD72iPRzP"
      },
      "id": "uu6kD72iPRzP",
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/drive/MyDrive/final/augmented_train3.csv')"
      ],
      "metadata": {
        "id": "efKSTlgxP2g_"
      },
      "id": "efKSTlgxP2g_",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnqYC7y2P2nC",
        "outputId": "95b4c30a-86b8-4380-8765-bab14ba1793f"
      },
      "id": "BnqYC7y2P2nC",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(480289, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#importing the cleaned and preprocessed test csv file exported from jupyter notebook\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/final/cleaned_test.csv')"
      ],
      "metadata": {
        "id": "OCG466XiP2p5"
      },
      "id": "OCG466XiP2p5",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXfBlwqARGoc",
        "outputId": "0c69dcaa-5c7f-4345-fee0-780e9e5dc906"
      },
      "id": "cXfBlwqARGoc",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15441, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#importing the cleaned and preprocessed test csv file exported from jupyter notebook\n",
        "val_df = pd.read_csv('/content/drive/MyDrive/final/cleaned_val.csv')"
      ],
      "metadata": {
        "id": "xp0CHndpRGrE"
      },
      "id": "xp0CHndpRGrE",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P80RedmZRGtV",
        "outputId": "f770aeff-7d65-4139-d075-4ccad787265d"
      },
      "id": "P80RedmZRGtV",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15442, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#shuffling all the rows so that original and augmented data rows gets mixed\n",
        "train_df = df.sample(frac=1, random_state=42)"
      ],
      "metadata": {
        "id": "FFLCJAlNRGvX"
      },
      "id": "FFLCJAlNRGvX",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reset index\n",
        "train_df.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "kbIAvkCoRGxs"
      },
      "id": "kbIAvkCoRGxs",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WQxfphIPRWT2"
      },
      "id": "WQxfphIPRWT2",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "FOR ORIGINAL DATA WITHOUT AUGMENTATION"
      ],
      "metadata": {
        "id": "MS1t7oKUR8GB"
      },
      "id": "MS1t7oKUR8GB"
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset"
      ],
      "metadata": {
        "id": "zuGAUWASSGZj"
      },
      "id": "zuGAUWASSGZj",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_cnn = load_dataset('cnn_dailymail','3.0.0')\n",
        "split_lengths = [len(dataset_cnn[split])for split in dataset_cnn]\n",
        "\n",
        "print(f\"Split lengths: {split_lengths}\")\n",
        "print(f\"Features: {dataset_cnn['train'].column_names}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121,
          "referenced_widgets": [
            "adf2182f1848454cbd0ccbfd8f3b5f02",
            "a94913c9fe5f4aee9264264ab0957b79",
            "b7874b0cf42e4148ac691a876b4e2635",
            "774facdc701d4bde8eefdee0d0d0886f",
            "9bcf7f8a1e8e49bfaee4c9874aaa88a2",
            "2285d12fc1244b44b997c20e047b7189",
            "ae43072aa1a04419853b29b1cacf44df",
            "854f444c2c98496581399d785e8916af",
            "218b7a516cfb4934ba4a82ecbc2ff8a1",
            "da6c22d80a0e49f2b850baf13f8a629d",
            "bddd1c99b6b54cd485d847c2df8052cb"
          ]
        },
        "id": "oR143abhRWVs",
        "outputId": "ce4e265d-efde-44cd-e80e-f132c4717a17"
      },
      "id": "oR143abhRWVs",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset cnn_dailymail (/root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/1b3c71476f6d152c31c1730e83ccb08bcf23e348233f4fcc11e182248e6bf7de)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "adf2182f1848454cbd0ccbfd8f3b5f02"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Split lengths: [287113, 13368, 11490]\n",
            "Features: ['article', 'highlights', 'id']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fRXGrjAIRWYO"
      },
      "id": "fRXGrjAIRWYO",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y-aDP8n2RWav"
      },
      "id": "Y-aDP8n2RWav",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade accelerate\n",
        "from functools import partial\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UaZiCw8BRWdF",
        "outputId": "ce1ee061-0e30-48fe-fd40-a8ab855e183a"
      },
      "id": "UaZiCw8BRWdF",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.19.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.24.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (16.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->accelerate) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->accelerate) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers==4.28.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kj2oNvfBRWfb",
        "outputId": "1500e706-e981-4ba3-c90d-14511fd2bf14"
      },
      "id": "kj2oNvfBRWfb",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers==4.28.0 in /usr/local/lib/python3.10/dist-packages (4.28.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (0.14.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (1.24.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.0) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.0) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.0) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# use cnn dataset as example, with first original as training data\n",
        "\n",
        "train_texts, train_labels = dataset_cnn['train'][:30000]['article'], dataset_cnn['train']['highlights'][:30000]\n",
        "#train_texts, train_labels = dataset['train']['document'], dataset['train']['summary']\n",
        "val_texts, val_labels = dataset_cnn['validation']['article'][:2000], dataset_cnn['validation']['highlights'][:2000]"
      ],
      "metadata": {
        "id": "No87p91rPts6"
      },
      "id": "No87p91rPts6",
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_checkpoint = 'google/pegasus-multi_news'\n",
        "# about 8 mins to finish for the whole dataset\n",
        "train_dataset, val_dataset, _ = prepare_data(model_checkpoint, train_texts, train_labels, val_texts, val_labels)\n"
      ],
      "metadata": {
        "id": "7ZHGNQaqPtyb"
      },
      "id": "7ZHGNQaqPtyb",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# only about 1 minute\n",
        "trainer = prepare_fine_tuning(model_checkpoint, train_dataset, val_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPxaucbfYLil",
        "outputId": "8c79f64e-1996-444e-ff80-77f6bbb86e80"
      },
      "id": "JPxaucbfYLil",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 15.1 s, sys: 4.2 s, total: 19.3 s\n",
            "Wall time: 13.9 s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1243: FutureWarning: `--adafactor` is deprecated and will be removed in version 5 of 🤗 Transformers. Use `--optim adafactor` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "yNJ-FgY6xfcv",
        "outputId": "7ff4e78c-0dc3-4d4d-e450-70f370b0ae0c"
      },
      "id": "yNJ-FgY6xfcv",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [20/20 03:04, Epoch 20/20]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>8.673236</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.851900</td>\n",
              "      <td>8.652978</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>1.851900</td>\n",
              "      <td>8.621410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.813200</td>\n",
              "      <td>8.564925</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=20, training_loss=1.8325450897216797, metrics={'train_runtime': 195.9177, 'train_samples_per_second': 0.204, 'train_steps_per_second': 0.102, 'total_flos': 115578576568320.0, 'train_loss': 1.8325450897216797, 'epoch': 20.0})"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]\n",
        "\n",
        "rouge_metric = load_metric('rouge')"
      ],
      "metadata": {
        "id": "3vhzHJ4yxfvc"
      },
      "id": "3vhzHJ4yxfvc",
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pegtokenizer = PegasusTokenizer.from_pretrained(model_checkpoint)"
      ],
      "metadata": {
        "id": "QkoCs9fQ5Lgt"
      },
      "id": "QkoCs9fQ5Lgt",
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = calculate_metric_on_test_ds(\n",
        "    dataset_cnn['test'][:500], rouge_metric, trainer.model, pegtokenizer, batch_size = 3, column_text = 'article', column_summary= 'highlights'\n",
        ")\n",
        "\n",
        "rouge_dict = dict((rn, score[rn].mid.fmeasure ) for rn in rouge_names )\n",
        "\n",
        "pd.DataFrame(rouge_dict, index = [f'pegasus'] )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GQfjIJX1xf9r",
        "outputId": "44126c26-e017-4dac-83ef-4c0c646bd8bd"
      },
      "id": "GQfjIJX1xf9r",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/167 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(95399)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 1/167 [00:24<1:07:06, 24.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(88480)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 2/167 [00:47<1:05:07, 23.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(95967)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 3/167 [01:10<1:04:13, 23.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(87575)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 4/167 [01:33<1:02:39, 23.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(88699)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 5/167 [01:56<1:02:03, 22.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(92531)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▎         | 6/167 [02:19<1:02:27, 23.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(93359)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 7/167 [02:42<1:01:10, 22.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(94811)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▍         | 8/167 [03:04<1:00:38, 22.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(95607)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 9/167 [03:28<1:01:04, 23.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(94494)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 10/167 [03:51<1:00:04, 22.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(95534)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 11/167 [04:13<59:31, 22.89s/it]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(91755)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 12/167 [04:38<1:00:19, 23.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(93454)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 13/167 [05:02<1:00:09, 23.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(95460)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 14/167 [05:24<59:17, 23.25s/it]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(91955)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▉         | 15/167 [05:48<59:01, 23.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(92172)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|▉         | 16/167 [06:10<58:03, 23.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(93338)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 17/167 [06:33<57:32, 23.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(92610)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█         | 18/167 [06:57<57:35, 23.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(87023)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█▏        | 19/167 [07:20<56:56, 23.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(91223)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 20/167 [07:42<56:05, 22.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(95379)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 21/167 [08:06<56:12, 23.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(95722)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 22/167 [08:28<55:37, 23.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(95775)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 23/167 [08:51<55:02, 22.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(92627)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 24/167 [09:14<54:20, 22.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(94709)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▍        | 25/167 [09:38<54:47, 23.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(92818)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 26/167 [10:01<54:47, 23.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(94872)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 27/167 [10:24<53:52, 23.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(95616)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 28/167 [10:47<53:48, 23.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(90423)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 29/167 [11:10<53:13, 23.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(89875)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 30/167 [11:33<52:47, 23.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(88737)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|█▊        | 31/167 [11:56<52:12, 23.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(95659)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|█▉        | 32/167 [12:19<51:30, 22.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(94712)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|█▉        | 33/167 [12:41<50:55, 22.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(89286)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 34/167 [13:05<51:17, 23.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(95642)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██        | 35/167 [13:28<50:41, 23.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(94229)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 36/167 [13:51<49:52, 22.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(92614)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 37/167 [14:19<53:07, 24.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(95341)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 38/167 [14:42<51:54, 24.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(89703)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 39/167 [15:05<50:32, 23.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(89786)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 40/167 [15:28<49:47, 23.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(92025)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▍       | 41/167 [15:51<49:14, 23.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(94429)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 42/167 [16:13<47:59, 23.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(92771)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 43/167 [16:36<47:10, 22.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(95386)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▋       | 44/167 [16:59<47:16, 23.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(90981)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 45/167 [17:22<46:48, 23.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(93338)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 46/167 [17:45<46:15, 22.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(92106)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 47/167 [18:09<46:43, 23.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(92325)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▊       | 48/167 [18:31<45:27, 22.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(94815)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▉       | 49/167 [18:54<44:58, 22.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(90091)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|██▉       | 50/167 [19:18<45:20, 23.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(92726)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|███       | 51/167 [19:41<44:31, 23.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(93262)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|███       | 52/167 [20:04<44:16, 23.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(95775)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 53/167 [20:27<44:00, 23.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(94136)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 54/167 [20:50<43:17, 22.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(95134)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 55/167 [21:13<42:51, 22.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(95103)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▎      | 56/167 [21:35<42:17, 22.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(93872)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 57/167 [21:59<42:11, 23.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(90919)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▍      | 58/167 [22:22<41:44, 22.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(90955)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▌      | 59/167 [22:45<41:25, 23.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(94393)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 60/167 [23:07<40:54, 22.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(95134)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|███▋      | 61/167 [23:30<40:20, 22.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(89792)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|███▋      | 62/167 [23:53<40:11, 22.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(90254)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 63/167 [24:16<39:37, 22.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(89872)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 64/167 [24:38<39:00, 22.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(93615)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 39%|███▉      | 65/167 [25:02<38:51, 22.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(92542)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|███▉      | 66/167 [25:25<38:38, 22.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(94471)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 67/167 [25:47<38:04, 22.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(88064)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|████      | 68/167 [26:10<37:49, 22.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(95693)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|████▏     | 69/167 [26:33<37:26, 22.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(94815)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 70/167 [26:56<37:11, 23.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(91808)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 71/167 [27:20<37:03, 23.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(93301)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 72/167 [27:42<36:13, 22.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(95338)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▎     | 73/167 [28:05<35:55, 22.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(91134)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 74/167 [28:28<35:36, 22.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(95452)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▍     | 75/167 [28:51<35:05, 22.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(93003)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 76/167 [29:15<34:58, 23.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(90561)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 77/167 [29:37<34:26, 22.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(88903)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 78/167 [30:01<34:14, 23.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(95193)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 79/167 [30:24<34:05, 23.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(95608)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 80/167 [30:46<33:05, 22.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(95720)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|████▊     | 81/167 [31:09<32:32, 22.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(92819)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|████▉     | 82/167 [31:32<32:25, 22.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(90214)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|████▉     | 83/167 [31:54<31:53, 22.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(95921)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 84/167 [32:17<31:30, 22.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(94385)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|█████     | 85/167 [32:41<31:25, 22.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(94815)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|█████▏    | 86/167 [33:03<30:57, 22.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(94226)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 87/167 [33:27<30:49, 23.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(95987)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 88/167 [33:50<30:21, 23.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(81449)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 89/167 [34:13<29:54, 23.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(83415)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 90/167 [34:38<30:20, 23.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(95194)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 91/167 [35:01<29:41, 23.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(84958)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▌    | 92/167 [35:23<28:54, 23.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(96092)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 93/167 [35:47<28:37, 23.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(95905)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▋    | 94/167 [36:10<28:06, 23.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(93338)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 95/167 [36:32<27:34, 22.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(93566)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 96/167 [36:56<27:26, 23.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(91223)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 97/167 [37:18<26:47, 22.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(84650)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|█████▊    | 98/167 [37:42<26:37, 23.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(94961)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|█████▉    | 99/167 [38:05<26:13, 23.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(87371)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|█████▉    | 100/167 [38:28<25:39, 22.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(94726)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 101/167 [38:51<25:33, 23.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(88950)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 61%|██████    | 102/167 [39:14<25:02, 23.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(85360)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 103/167 [39:38<24:55, 23.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(94542)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 104/167 [40:02<24:32, 23.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(89872)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|██████▎   | 105/167 [40:25<24:07, 23.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(91438)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|██████▎   | 106/167 [40:48<23:39, 23.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(94694)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 107/167 [41:11<23:09, 23.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(80894)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▍   | 108/167 [41:34<22:50, 23.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(92609)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▌   | 109/167 [41:57<22:21, 23.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(93266)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 110/167 [42:20<21:59, 23.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(94864)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▋   | 111/167 [42:44<21:51, 23.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(95790)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 112/167 [43:07<21:12, 23.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(95607)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 113/167 [43:32<21:18, 23.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(95369)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 114/167 [43:55<20:42, 23.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(95722)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|██████▉   | 115/167 [44:19<20:27, 23.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(95698)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|██████▉   | 116/167 [44:42<19:57, 23.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(95616)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 117/167 [45:05<19:28, 23.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(94183)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|███████   | 118/167 [45:28<19:00, 23.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(92781)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|███████▏  | 119/167 [45:51<18:31, 23.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(92329)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 120/167 [46:15<18:16, 23.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(92396)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 121/167 [46:38<17:49, 23.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(93768)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|███████▎  | 122/167 [47:01<17:22, 23.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(95239)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▎  | 123/167 [47:24<16:57, 23.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(96004)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▍  | 124/167 [47:46<16:24, 22.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(96092)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▍  | 125/167 [48:09<15:58, 22.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(89328)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 126/167 [48:32<15:40, 22.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(95192)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 127/167 [48:55<15:17, 22.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(95452)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|███████▋  | 128/167 [49:19<15:04, 23.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(95023)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|███████▋  | 129/167 [49:41<14:33, 22.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(95616)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 130/167 [50:05<14:15, 23.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(95338)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 131/167 [50:28<13:52, 23.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(94462)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|███████▉  | 132/167 [50:50<13:21, 22.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(90353)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|███████▉  | 133/167 [51:13<13:01, 23.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(95192)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 134/167 [51:36<12:36, 22.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(95853)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 81%|████████  | 135/167 [51:59<12:09, 22.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(93733)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 81%|████████▏ | 136/167 [52:22<11:53, 23.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(88263)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▏ | 137/167 [52:45<11:26, 22.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(95059)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 138/167 [53:07<10:57, 22.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(93768)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 139/167 [53:30<10:39, 22.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(95702)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 140/167 [53:54<10:21, 23.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(95806)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 141/167 [54:16<09:53, 22.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(90851)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▌ | 142/167 [54:41<09:49, 23.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(94571)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 143/167 [55:04<09:21, 23.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(88275)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 144/167 [55:28<09:00, 23.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(94710)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 145/167 [55:50<08:29, 23.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(96037)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 146/167 [56:13<08:01, 22.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(95916)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 147/167 [56:36<07:42, 23.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(96000)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▊ | 148/167 [56:59<07:18, 23.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(95469)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▉ | 149/167 [57:22<06:51, 22.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(83548)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|████████▉ | 150/167 [57:45<06:31, 23.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(93630)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 151/167 [58:08<06:09, 23.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(92614)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%|█████████ | 152/167 [58:32<05:47, 23.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(92285)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 153/167 [58:55<05:23, 23.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(95335)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 154/167 [59:17<04:57, 22.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(93262)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 155/167 [59:41<04:37, 23.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(93781)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 156/167 [1:00:04<04:15, 23.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(95616)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 157/167 [1:00:27<03:50, 23.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(95932)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▍| 158/167 [1:00:50<03:27, 23.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(95702)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 159/167 [1:01:13<03:03, 22.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(94872)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 160/167 [1:01:36<02:40, 23.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(95864)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▋| 161/167 [1:01:59<02:17, 22.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(95835)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 162/167 [1:02:21<01:54, 22.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(95814)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 163/167 [1:02:45<01:32, 23.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(94771)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 164/167 [1:03:08<01:09, 23.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(93386)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|█████████▉| 165/167 [1:03:32<00:46, 23.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([3, 1024])\n",
            "max input_ids value: tensor(93736)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|█████████▉| 166/167 [1:03:55<00:23, 23.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128])\n",
            "torch.Size([3, 1024])\n",
            "input_ids shape: torch.Size([2, 1024])\n",
            "max input_ids value: tensor(94693)\n",
            "vocabulary size: 96103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 167/167 [1:04:12<00:00, 23.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 128])\n",
            "torch.Size([2, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          rouge1    rouge2    rougeL  rougeLsum\n",
              "pegasus  0.27176  0.096749  0.180235   0.213639"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-25d64dba-b3b5-4c1b-949a-3f6e7797a84c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rouge1</th>\n",
              "      <th>rouge2</th>\n",
              "      <th>rougeL</th>\n",
              "      <th>rougeLsum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>pegasus</th>\n",
              "      <td>0.27176</td>\n",
              "      <td>0.096749</td>\n",
              "      <td>0.180235</td>\n",
              "      <td>0.213639</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-25d64dba-b3b5-4c1b-949a-3f6e7797a84c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-25d64dba-b3b5-4c1b-949a-3f6e7797a84c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-25d64dba-b3b5-4c1b-949a-3f6e7797a84c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "accelerator": "TPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "adf2182f1848454cbd0ccbfd8f3b5f02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a94913c9fe5f4aee9264264ab0957b79",
              "IPY_MODEL_b7874b0cf42e4148ac691a876b4e2635",
              "IPY_MODEL_774facdc701d4bde8eefdee0d0d0886f"
            ],
            "layout": "IPY_MODEL_9bcf7f8a1e8e49bfaee4c9874aaa88a2"
          }
        },
        "a94913c9fe5f4aee9264264ab0957b79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2285d12fc1244b44b997c20e047b7189",
            "placeholder": "​",
            "style": "IPY_MODEL_ae43072aa1a04419853b29b1cacf44df",
            "value": "100%"
          }
        },
        "b7874b0cf42e4148ac691a876b4e2635": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_854f444c2c98496581399d785e8916af",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_218b7a516cfb4934ba4a82ecbc2ff8a1",
            "value": 3
          }
        },
        "774facdc701d4bde8eefdee0d0d0886f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da6c22d80a0e49f2b850baf13f8a629d",
            "placeholder": "​",
            "style": "IPY_MODEL_bddd1c99b6b54cd485d847c2df8052cb",
            "value": " 3/3 [00:02&lt;00:00,  1.54it/s]"
          }
        },
        "9bcf7f8a1e8e49bfaee4c9874aaa88a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2285d12fc1244b44b997c20e047b7189": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae43072aa1a04419853b29b1cacf44df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "854f444c2c98496581399d785e8916af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "218b7a516cfb4934ba4a82ecbc2ff8a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "da6c22d80a0e49f2b850baf13f8a629d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bddd1c99b6b54cd485d847c2df8052cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}